{"cells":[{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint\nimport numpy as np\nimport os, tempfile\nimport csv\nimport string\nimport random\nimport collections\nimport math\nimport heapq\n\n#// Import & lecture du fichier csv\nfile_location = \"/dbfs/FileStore/tables/training.csv\"\ntext=open(file_location, encoding='ISO-8859-1')\nfile_reader = csv.reader(text)\n\nreader=[]\nclassification=[]\n\n#// Lecture du contenu du fichier csv et utilisation des structures de données\n#// classification : [class_tweet_1, class_tweet_2, ... , class_tweet_i, ...]\n#// reader : [tweet_1, tweet_2, ... , tweet_i, ...]\nfor tuple in file_reader:\n  classification.append(tuple[0])\n  reader.append([tuple[5]])\n      \n#// --- Fonction d'ajout d'un élément un certain nombre de fois dans une liste ---\ndef addXtimesYInList(X,Y,Liste):\n\tfor i in range(X):\n\t\tListe.append(Y)\n\n#// --- Fonction de calcul du nb d'itérations d'un mot dans une phrase splitée ---\ndef nbIterationsMotdansPhrase(recherche,phrase):\n    iterations=0\n    for mot in phrase:\n        if mot == recherche:\n            iterations=iterations+1\n    return iterations\n\n#// --- Fonction qui renvoie si un mot est contenu un set ou non ---\ndef WordIsInSet(word,set):\n    for item in set:\n        if word==item :\n            return True\n    return False\n\n#// --- Fonction qui vérifie s'il existe un pattern vérifié ---\ndef RespectPattern(phrase):\n    size=len(phrase)\n    if WordIsInSet(phrase[0],HFWords):                  #// Premier mot est un HFW\n        if WordIsInSet(phrase[size-1],HFWords):         #// Dernier mot est un HFW\n            for i in range(1,size-1):\n                if WordIsInSet(phrase[i],CWords):       #// Contient un CW ou +\n                    return True\n    return False\n\n#// --- Fonction de calcul du nb de ! dans une phrase splitée ---\ndef NbExclamat(phrase):\n    i=0\n    for s in phrase:\n        i=i+s.count('!')\n    return i\n\n#// --- Fonction de calcul du nb de ? dans une phrase splitée ---\ndef NbQuest(phrase):\n    i=0\n    for s in phrase:\n        i=i+s.count('?')\n    return i\n\n#// --- Fonction de calcul du nb de quotes dans une phrase splitée ---\ndef NbQuotes(phrase):\n    i=0\n    for s in phrase:\n        i=i+s.count('`')\n    return i\n\n#// --- Fonction de calcul du nb de mots en maj dans une phrase splitée ---\ndef NbCapitalized(phrase):\n    i=0\n    for j in range(len(phrase)):\n        if phrase[j].isupper():\n            i=i+1\n    return i\n\n#// --- Fonction qui renvoie une liste d'indexs des tweets similaires ---\ndef similarity(list_of_words,set):\n  lst=[]\n  for k in range(len(list_of_words)):\n    for i in range(len(set)):\n      for j in range(len(set[i])):\n        if set[i][j]==list_of_words[k]:\n          lst.append(i)\n  return lst\n\n#// --- Fonction qui renvoie la distance euclidienne entre 2 points ---\ndef compute_distance(elem1,elem2):\n  return math.sqrt(math.pow(elem1[0]-elem2[0],2)+math.pow(elem1[1]-elem2[1],2)+math.pow(elem1[2]-elem2[2],2)+math.pow(elem1[3]-elem2[3],2))\n\n#// --- Fonction qui renvoie l'index d'un élément dans une liste ---\ndef index_of(elem,list):\n  for i in range(len(list)):\n    if list[i]==elem:\n      return i\n\n#// --- Fonction qui renvoie les k plus petits éléments d'une liste ---\ndef get_k_minimums_from_list(k,list):\n  k_list=heapq.nsmallest(k, list)\n  mins=[]\n  for i in range(len(k_list)):\n    mins.append(index_of(k_list[i],list))\n  return mins\n\n#// --- Fonction qui renvoie les k plus proches voisins ---\ndef get_k_nearest(k,elem,list_elem):\n  tab=[]\n  for i in range(len(list_elem)):\n    tab.append(compute_distance(elem,list_elem[i]))\n  return get_k_minimums_from_list(k,tab)\n\n#// --- Fonction qui donne la classe majoritaire d'un set ---\n#// 0 = negative, 2 = neutral, 4 = positive\ndef get_majority_class(elem,elem_classes):\n  proportions=[0,0,0]\n  for i in range(len(elem)):\n    if elem_classes[elem[i]]==0:\n      proportions[0]=proportions[0]+1\n    elif elem_classes[elem[i]]==2:\n      proportions[1]=proportions[1]+1\n    elif elem_classes[elem[i]]==4 :\n      proportions[2]=proportions[2]+1\n  return index_of(max(proportions),proportions)\n\n#// --- Fonction d'évaluation du modèle ---\ndef evaluate(experimentation,reality):\n  good_ones=0\n  bad_ones=0\n  for i in range(len(experimentation)):\n    if str(experimentation[i])==reality[i]:\n      good_ones=good_ones+1\n    else:\n      bad_ones=bad_ones+1\n  return good_ones/len(experimentation)\n\n#// Definition de vecteurs utiles\nNbNgramsInTweet=[]\nNbWordsInTweet=[]\nCountWords=[]\nFrequencies=[]\nPatternNumb=[]\nPatternFreq=[]\nFrequenciesInTweet=[]\nPunctuationFeatureInTweet=[]\nPunctuationFeature=[]\nHFWords=[]\nRWords=[]\nCWords=[]\nWordsInTweet=[]\nFeaturesVector = []\nTestingDataFeatures = []\nSimilaritiesByWords=[]     #// SimilaritiesByWords = [[sim_1_1,sim_2_1,sim_3_1],[sim_1_2,sim_2_2,sim_3_2]]\nKNeighboors=[]\nResults=[]\nWordsInTweet=[]\n\n#// Définition de vecteurs de ngrams\nngrams1=[]\nngrams2=[]\nngrams3=[]\nngrams4=[]\nngrams5=[]\nngrams1brut=[]\nngrams2brut=[]\nngrams3brut=[]\nngrams4brut=[]\nngrams5brut=[]\nngrams1unite=[]\nngrams2unite=[]\nngrams3unite=[]\nngrams4unite=[]\nngrams5unite=[]\n\n#// Pre-processing de la data\ni=0\nfor l in reader :\n    #// Suppression des #,@,RT, et liens\n    l[0] = \" \".join(filter(lambda x:x[0]!='#' and x[0]!='@' and (not x.startswith('http')) and x!='RT' and x!=\".\" and x!=\",\" and x!=\"!\" and x!=\"?\" and x!=\";\" and x!=\":\", l[0].split()))\n    l=l[0].split()\n    WordsInTweet.append(l)\n    \n    ngrams1unite = [(l[i]) for i in range(len(l))]\n    ngrams2unite = [(l[i],l[i+1]) for i in range(len(l)-1)]\n    ngrams3unite = [(l[i],l[i+1],l[i+2]) for i in range(len(l)-2)]\n    ngrams4unite = [(l[i],l[i+1],l[i+2],l[i+3]) for i in range(len(l)-3)]\n    ngrams5unite = [(l[i],l[i+1],l[i+2],l[i+3],l[i+4]) for i in range(len(l)-4)]\n\n    NbNgramsInTweet.append(len(ngrams1unite)+len(ngrams2unite)+len(ngrams3unite)+len(ngrams4unite)+len(ngrams5unite))\n\n\t#// Transformer en liste la structure de Counter\n    comptagengrams1unite = collections.Counter(ngrams1unite).most_common()\n    comptagengrams2unite = collections.Counter(ngrams2unite).most_common()\n    comptagengrams3unite = collections.Counter(ngrams3unite).most_common()\n    comptagengrams4unite = collections.Counter(ngrams4unite).most_common()\n    comptagengrams5unite = collections.Counter(ngrams5unite).most_common()\n\n\t#// Mettre à jour le compteur de ngrams totaux\n    for i in range(len(comptagengrams1unite)):\n        addXtimesYInList(comptagengrams1unite[i][1],comptagengrams1unite[i][0],ngrams1brut)\n    for i in range(len(comptagengrams2unite)):\n        addXtimesYInList(comptagengrams2unite[i][1],comptagengrams2unite[i][0],ngrams2brut)\n    for i in range(len(comptagengrams3unite)):\n        addXtimesYInList(comptagengrams3unite[i][1],comptagengrams3unite[i][0],ngrams3brut)\n    for i in range(len(comptagengrams4unite)):\n        addXtimesYInList(comptagengrams4unite[i][1],comptagengrams4unite[i][0],ngrams4brut)\n    for i in range(len(comptagengrams5unite)):\n        addXtimesYInList(comptagengrams5unite[i][1],comptagengrams5unite[i][0],ngrams5brut)\n\n#// Création du recap des Ngrams de tous les tweets sous forme de tables de hash\nngrams1 = { i : ngrams1brut.count(i) for i in ngrams1brut }\nngrams2 = { i : ngrams2brut.count(i) for i in ngrams2brut }\nngrams3 = { i : ngrams3brut.count(i) for i in ngrams3brut }\nngrams4 = { i : ngrams4brut.count(i) for i in ngrams4brut }\nngrams5 = { i : ngrams5brut.count(i) for i in ngrams5brut }\n\n#// Analyse de tous les tweets et création d'un tableau de tableau avec les mots et le nb d'apparition\n#// Ex.:  CountWords=[ [(tweet1_mot1,freq_t1_m1),(tweet1_mot2,freq_t1_m2)] , [(tweet2_mot1,freq_t2_m1),(tweet2_mot2,freq_t2_m2)] ]\nindex=0\nfor l in reader :\n    l=l[0].split()\n    CountWords.append([])\n    CountWords[index].append({l[i] : nbIterationsMotdansPhrase(l[i],l) for i in range(len(l))})\n    NbWordsInTweet.append(len(l))\n    index=index+1\n\n#// Calcul des fréquences d'apparition des mots dans les tweets\n#// Ex.:  FrequenciesInTweet=[ [tweet1 {mot_1 : freq_mot_1_t1},{mot_2 : freq_mot_2_t1}] , [tweet2 {mot_1 : freq_mot_1_t2},{mot_2 : freq_mot_2_t2}] ]\nindex=0\nfor l in reader :\n    l=l[0].split()\n    FrequenciesInTweet.append([])\n    for i in range(len(l)):\n        FrequenciesInTweet[index].append({l[i] : CountWords[index][0].get(l[i])/ngrams1[l[i]]})\n    index=index+1\n\n#// Calcul des fréquences d'apparition des mots dans les tweets par rapport au total\n#// Ex.:  FrequenciesInTweet=[ [tweet1 {mot_1 : freq_mot_1},{mot_2 : freq_mot_2}] , [tweet2 {mot_1 : freq_mot_1},{mot_2 : freq_mot_2}] ]\nindex = 0\nNbWords = len(ngrams1brut)\nfor l in reader :\n    l=l[0].split()\n    Frequencies.append([])\n    for i in range(len(l)):\n        Frequencies[index].append([l[i] , ngrams1[l[i]]/NbWords])\n    index=index+1\n\n#// Création des HFWords, des CWords et RWords\nfor tweet in Frequencies :\n    for i in range(len(tweet)) :\n        if tweet[i][1]>=0.00001 and tweet[i][1]<=0.000505:\n            HFWords.append(tweet[i][0])\n        elif tweet[i][1]>=0.000505 and tweet[i][1]<=0.001:\n            CWords.append(tweet[i][0])\n        else:\n            RWords.append(tweet[i][0])\n\n#// Calcul de la pattern feature\nindex=0\nfor l in reader :\n    l=l[0].split()\n    PatternNumb.append(0)\n    PatternFreq.append(0)\n    for i in range(len(l)):\n        if RespectPattern(l):\n            PatternNumb[index]=PatternNumb[index]+1\n            PatternFreq[index]=PatternNumb[index]/sum(PatternNumb)\n    index=index+1\n\n\n#// Calculs intermédiaires : punctuation feature par tweet\nfor l in reader :\n    l=l[0].split()\n    PunctuationFeatureInTweet.append(len(l)+NbExclamat(l)+NbQuest(l)+NbQuotes(l)+NbCapitalized(l))\n\n#// Calcul de la punctuation feature totale\n#// Mw = max(NbWordsInTweet)\n#// Mng = max(NbNgramsInTweet)\n#// Mpa = max(PatternNumb)\n#// Mp = max(PunctuationFeatureInTweet)\nindex=0\nfor i in range(len(reader)) :\n    PunctuationFeature.append(PunctuationFeatureInTweet[i]/(max(PunctuationFeatureInTweet)*(max(NbWordsInTweet)+max(NbNgramsInTweet)+max(PatternNumb))/3))\n    index=index+1\n\nNbTotalNgram = sum(NbNgramsInTweet)\n\nfor i in range(len(NbNgramsInTweet)):\n    NbNgramsInTweet[i]=NbNgramsInTweet[i]/NbTotalNgram\n\n# NbNgramsInTweet             #wNgrams\n# NbWordsInTweet              #wWords\n# PatternFreq                 #wPattern\n# PunctuationFeature          #wPunctuation\n\nindex=0\nfor l in reader :\n    FeaturesVector.append([NbNgramsInTweet[index],NbWordsInTweet[index],PatternFreq[index],PunctuationFeature[index]])\n    index=index+1\n    \n#// Séparation Training / Testing\n\n#// Calcul des proportions\nProportionsTweets = [len(FeaturesVector),0,0]\nProportionsTweets[1]=math.floor(0.7*ProportionsTweets[0])\nProportionsTweets[2]=ProportionsTweets[0]-ProportionsTweets[1]\n\n#// Création des RDDs\nFeatures_RDD=sc.parallelize(FeaturesVector)\n\n#// SimilaritiesByWords = [[sim_1_1,sim_2_1,sim_3_1],[sim_1_2,sim_2_2,sim_3_2]]\n\nfor i in range(ProportionsTweets[2]) :\n  TestingDataFeatures.append(Features_RDD.collect()[i])\n  SimilaritiesByWords.append(similarity(WordsInTweet[i],WordsInTweet)) #// liste de liste des t similaires [[t1_sim_A,t2_sim_A],[t1_sim_B,t2_sim_B]]\n  SimilarsFeatures=[]\n  for j in range(len(SimilaritiesByWords[i])):\n    SimilarsFeatures.append(Features_RDD.collect()[SimilaritiesByWords[i][j]])  #// j ème ds similars [i] = j ème dans i ème [i][j] ds SimilaritiesByWords\n  list_index = get_k_nearest(150,Features_RDD.collect()[i],SimilarsFeatures) #// Liste d'indices des + proches\n  final_list=[]\n  for j in range(len(list_index)):\n    final_list.append(SimilaritiesByWords[i][list_index[j]])\n  KNeighboors.append(final_list)\n  Results.append(get_majority_class(KNeighboors[i],classification))\n\nprint(evaluate(Results,classification))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1.0\n</div>"]}}],"execution_count":1}],"metadata":{"name":"BigDataProjet","notebookId":799711869149350},"nbformat":4,"nbformat_minor":0}
